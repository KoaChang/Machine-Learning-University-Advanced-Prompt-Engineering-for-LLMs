{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0d1368",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "\n",
    "# <a name=\"0\">MLU Advanced Prompt Engineering for LLMs</a>\n",
    "## <a name=\"0\">Lab 4: Reason and Act (ReAct)</a>\n",
    "\n",
    "This notebook introduces ReAct, a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia, code interpreters) to incorporate additional information into the reasoning. \n",
    "\n",
    "1. <a href=\"#1\">Import libraries</a>\n",
    "2. <a href=\"#2\">Set up Bedrock for inference</a>\n",
    "3. <a href=\"#3\">Reason and Act (ReAct)</a>\n",
    "    - <a href=\"#31\">LangChain tools</a>\n",
    "    - <a href=\"#32\">LangChain agents</a>\n",
    "4. <a href=\"#4\">ReAct examples</a>\n",
    "    - <a href=\"#41\">Time awareness</a>\n",
    "    - <a href=\"#42\">Calculator and code interpreter</a>\n",
    "    - <a href=\"#43\">Knowledge-intensive tasks</a>\n",
    "    - <a href=\"#44\">Decision-making tasks</a>\n",
    "    \n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "---\n",
    "\n",
    "<br/>\n",
    "You will be presented with coding activities to check your knowledge and understanding throughout the notebook whenever you see the MLU robot:\n",
    "\n",
    "<img style=\"display: block; margin-left: auto; margin-right: auto;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3020b5",
   "metadata": {},
   "source": [
    "### <a name=\"1\">1. Import libraries</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's start by installing all required packages as specified in the `requirements.txt` file and importing several libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dc09b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U pip --root-user-action=ignore\n",
    "!pip3 install -q -r requirements.txt --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae94383-c594-4fc8-9198-5b9eaebcb7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                     0.1.14\n",
      "langchain-aws                 0.1.6\n",
      "langchain-community           0.0.38\n",
      "langchain-core                0.1.52\n",
      "langchain-experimental        0.0.56\n",
      "langchain-text-splitters      0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b81748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from datetime import date, time\n",
    "\n",
    "#from langchain.llms.bedrock import Bedrock\n",
    "from langchain.tools import WikipediaQueryRun, tool\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.agents import AgentType, Tool, load_tools, initialize_agent\n",
    "#from langchain_community.llms import Bedrock\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mlu_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21e229-b076-4472-bb42-549e79738b3c",
   "metadata": {},
   "source": [
    "### <a name=\"2\">2. Set up Bedrock for inference</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To get started, set up Bedrock and instantiate an active `bedrock-runtime` to query LLMs. The code below leverages [LangChain's Bedrock integration](https://python.langchain.com/docs/integrations/llms/bedrock).\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px\">\n",
    "    <h4>A note on Bedrock API invocation</h4>\n",
    "\n",
    "Amazon Bedrock is generally available for all AWS customers. The provided lab for this course currently invokes Bedrock's external endpoint, which has access to Anthropic and AI21 models.\n",
    "\n",
    "For training and learning purposes, Amazon Bedrock is also available through an internal endpoint that allows accessing Amazon's Titan models. To use that instead, please follow the instructions in the <a href=\"https://w.amazon.com/bin/view/AmazonBedrock/Products/GetStarted/\">Amazon Bedrock Get Started wiki page</a>.\n",
    "</div>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7498ed-6091-46f5-a013-e1f5515cd6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `Bedrock` was deprecated in LangChain 0.0.34 and will be removed in 0.3. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import BedrockLLM`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "KEYS_INFERENCE = {\n",
    "    \"anthropic\": {\n",
    "        \"max_tokens\": \"max_tokens_to_sample\",\n",
    "        \"stop_sequences\": \"stop_sequences\",\n",
    "    },\n",
    "    \"ai21\": {\"max_tokens\": \"maxTokens\", \"stop_sequences\": \"stopSequences\"},\n",
    "    \"amazon\": {\"max_tokens\": \"maxTokenCount\", \"stop_sequences\": \"stopSequences\"},\n",
    "    \"mistral\": {\"max_tokens\": \"max_tokens\", \"stop_sequences\": \"stop_sequences\"}\n",
    "}\n",
    "\n",
    "\n",
    "# Define the bedrock-runtime client that will be used for predictions\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "########################### Select the LLM ###############################\n",
    "\n",
    "\n",
    "#bedrock_model_id = \"amazon.titan-text-lite-v1\"\n",
    "#bedrock_model_id = \"amazon.titan-text-express-v1\"\n",
    "#bedrock_model_id = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "bedrock_model_id = \"amazon.titan-text-premier-v1:0\"\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "# Each model has a different set of inference parameters\n",
    "model_provider = bedrock_model_id.split(\".\")[0]\n",
    "keys = KEYS_INFERENCE[model_provider]\n",
    "\n",
    "inference_modifier = {\n",
    "    #\"prompt\": '',\n",
    "    \"temperature\": 0.5,\n",
    "    keys[\"max_tokens\"]: 1024,\n",
    "    keys[\"stop_sequences\"]: [],\n",
    "}\n",
    "\n",
    "llm = Bedrock(\n",
    "    model_id=bedrock_model_id, client=bedrock_runtime, model_kwargs=inference_modifier\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e39bc-3f4a-4f12-b753-1d8ace2a0d6e",
   "metadata": {},
   "source": [
    "Next, use Bedrock for inference to test everything works as expected. \n",
    "\n",
    "We will first run the example with Titan Premier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7ef78f-9ee8-42f9-bad0-53451e940b10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm sorry, I cannot perform any functions for you. I'm a large language model and I'm not programmed for this."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Example model prompting\n",
    "\n",
    "greeting_prompt = \"Hello, what's the meaning of life?\"\n",
    "\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(llm(prompt=greeting_prompt)))\n",
    "display(Markdown(\"---\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709fa4e",
   "metadata": {},
   "source": [
    "### <a name=\"3\">3. Reason and Act (ReAct)</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "ReAct was introduced in [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629), by Yao et al. (2022) to explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner. **Reasoning traces**, elicited e.g. by CoT, help the model induce, track, and update action plans as well as handle exceptions. **Actions**, induced e.g. by action plan generation, allow it to interface with external sources, such as knowledge bases or environments, to gather additional information.\n",
    "\n",
    "The ReAct method involves augmenting prompts with relational constraints, allowing the LM to better capture the desired context. The key steps are as follows:\n",
    "\n",
    "- **Identify entities**: define the entities in the context that are relevant to the task.\n",
    "- **Formulate relations**: determine the relationships between the identified entities. These relations can be explicit (e.g., \"X is a type of Y\") or implicit (e.g., \"X and Y are often found together\").\n",
    "- **Augment prompts**: combine the identified entities and their relations into a structured prompt that guides the LM towards generating contextually relevant response.\n",
    "\n",
    "In general, ReAct outperforms CoT on question answering, fact verification, and decision making tasks. CoT might suffer from fact hallucination, however it is also true that ReAct's structural constraints reduce its flexibility in formulating reasoning steps. Also ReAct depends a lot on the information it's retrieving; non-informative search results might derail the model reasoning and lead to difficulty in recovering and reformulating thoughts.\n",
    "\n",
    "Prompting methods that **combine and support switching between ReAct and CoT+Self-Consistency generally outperform** all the other approaches.\n",
    "\n",
    "Below you will see an example of a Bedrock-hosted LLM improving its capabilities with ReAct via LangChain's built-in functionality that builds agents to perform tasks by combining the power of LLMs with different tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8ccbb",
   "metadata": {},
   "source": [
    "#### <a name=\"31\">3.1. LangChain tools</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "ReAct can be enhanced with specialized agents and tools. These can help in automating the process of identifying entities and relations, as well as in formulating structured prompts. \n",
    "\n",
    "Tools are functions that agents can use to interact with the world. These tools can be generic utilities (e.g. search), other chains, or even other agents. With tools, **LLMs can search the web, do math, run code**, and more. While the LangChain library provides a [substantial selection of pre-built tools](https://python.langchain.com/docs/integrations/tools/), in many real-world projects, we'll often find that existing tool might not work out-of-the-boxi as expected. Eventually we might need to modify existing tools or build entirely new ones.\n",
    "\n",
    "#### Custom Tools\n",
    "\n",
    "Let's start by building a custom tool to give models access to the current date, a piece of information that is very relevant to answer queries about the real world, and that LLMs do not have access to, as they lack awareness of present vs. past time.\n",
    "\n",
    "The tool below returns the current date regardless of the input. Note that we enter the purpose of the tool in its `description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9536d8-a42d-465e-b910-a60a9ec81e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "2024-07-10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@tool\n",
    "def current_date(text: str) -> str:\n",
    "    \"\"\"Returns today's date, use this for any questions related to knowing today's date. \\\n",
    "    When you use this function, the Action should be current_date. The Action Input should be \"\" \\\n",
    "    This function will always return today's date. \\\n",
    "    Any date math should occur outside this function.\"\"\"\n",
    "    return str(date.today())\n",
    "\n",
    "# Define the date tool\n",
    "date_tool = Tool(\n",
    "    name=\"DateTool\", func=current_date, description=\"Useful to retrieve the current date.\"\n",
    ")\n",
    "\n",
    "# Test date tool\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown((date_tool(\"Whatever I input, the output should be today's date.\"))))\n",
    "display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d04e39-f58d-4235-a33b-6d7d19e63c50",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Python interpreter\n",
    "\n",
    "LangChain supports the execution of Python code via the [PythonREPLTool](https://python.langchain.com/docs/integrations/toolkits/python) a tool to access Python's standard shell, or REPL (Read-Eval-Print Loop).\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px\">\n",
    "    <h4>A note on security best practices with LLMs</h4>\n",
    "\n",
    "The Python REPL tool is shown here as an example of what's possible to build with ReAct.\n",
    "<br/>\n",
    "This demo does not use or teach security best practices. You should not allow generative AI to run arbitrary code on production systems.</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178be215-0978-45fe-9afa-563f57b017f8",
   "metadata": {},
   "source": [
    "#### Wikipedia Tool\n",
    "\n",
    "The Wikipedia tool allows to retrieve information about people, places, companies, facts, historical events, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6627da0-3350-4f08-87fd-570937a5fd24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Page: Airplane\n",
       "Summary: An airplane (American English) or aeroplane (Commonwealth English), informally plane, is a fixed-wing aircraft that is propelled forward by thrust from a jet engine, propeller, or rocket engine. Airplanes come in a variety of sizes, shapes, and wing configurations. The broad spectrum of uses for airplanes includes recreation, transportation of goods and people, military, and research. Worldwide, commercial aviation transports more than four billion passengers annually on airliners and transports more than 200 billion tonne-kilometers of cargo annually, which is less than 1% of the world's cargo movement. Most airplanes are flown by a pilot on board the aircraft, but some are designed to be remotely or computer-controlled such as drones.\n",
       "The Wright brothers invented and flew the first airplane in 1903, recognized as \"the first sustained and controlled heavier-than-air powered flight\". They built on the works of George Cayley dating from 1799, when he set forth the concept of the modern airplane (and later built and flew models and successful passenger-carrying gliders) and the work of German pioneer of human aviation Otto Lilienthal, who, between 1867 and 1896, also studied heavier-than-air flight. Lilienthal's flight attempts in 1891 are seen as the beginning of human flight.\n",
       "Following its limited use in World War I, aircraft technology continued to develop. Airplanes had a presence in all the major battles of World War II. The first jet aircraft was the German Heinkel He 178 in 1939. The first jet airliner, the de Havilland Comet, was introduced in 1952. The Boeing 707, the first widely successful commercial jet, was in commercial service for more than 60 years, from 1958 to 2019.\n",
       "\n",
       "Page: Church of the United Brethren in Christ\n",
       "Summary: The Church of the United Brethren in Christ is an evangelical Christian denomination with churches in 17 countries. It is Protestant, with an episcopal structure and Arminian theology, with roots in the Mennonite and German Reformed communities of 18th-century Pennsylvania, as well as close ties to Methodism. It was organized in 1800 by Martin Boehm and Philip William Otterbein and is the first American denomination that was not transplanted from Europe.  It emerged from United Brethren churches that were at first unorganized, and not all of which joined this church when it was formally organized in 1800, following a 1789 conference at the Otterbein Church (Baltimore, Maryland).\n",
       "In 1889, a controversy over membership in secret societies such as the Freemasons, the proper way to modify the church's constitution, and other issues split the United Brethren into majority liberal and minority conservative blocs, the latter of which was led by Bishop Milton Wright (father of the Wright Brothers). Both groups continued to use the name Church of the United Brethren in Christ.\n",
       "The majority faction, known as the Church of the United Brethren in Christ (New Constitution), merged with the Evangelical Church in 1946 to form a new denomination known as the Evangelical United Brethren Church (EUB). This in turn merged in 1968 with The Methodist Church to form the United Methodist Church (UMC).\n",
       "The Wright-led faction, The Church of the United Brethren in Christ, Old Constitution, continues today as the denomination of about 550 congregations, with 47,300 members in fifteen countries. The US National Conference consists of about 200 churches and 25,000 members in the United States, plus mission districts in Haiti and India. The United States national office is located in Huntington, Indiana, as is the denomination's only college, Huntington University.\n",
       "\n",
       "Page: Shiva Ayyadurai\n",
       "Summary: V. A. Shiva Ayyadurai (born Vellayappa Ayyadurai Shiva on December 2, 1963) is an Indian-American engineer, politician, entrepreneur, and anti-vaccine activist. He has become known for promoting conspiracy theories, pseudoscience, and unfounded medical claims. Ayyadurai holds four degrees from the Massachuse"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Define the API wrapper for Wikipedia\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "\n",
    "# Define the Wikipedia tool with a description and the function to retrieve results from Wikipedia\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"wikipedia\",\n",
    "    func=wikipedia.run,\n",
    "    description=\"Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\",\n",
    ")\n",
    "\n",
    "# Test the defined Wikipedia tool\n",
    "display(Markdown(\"---\"))\n",
    "display(Markdown(wikipedia_tool(\"Who invented the airplane?\")))\n",
    "display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd7feff-410b-4d18-8a42-e1202043db6e",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto; padding-left: 50px; padding-right: 50px\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\"><b>Try creating more tools for other tasks.</b></br> For example, you can ask use <a href=\"https://python.langchain.com/docs/integrations/tools/yahoo_finance_news\">YahooFinanceNewsTool</a> to query for financial information from companies such as <code>AMZN</code>.\n",
    "</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0965f7-a74f-4677-affb-5d53c5e64925",
   "metadata": {},
   "source": [
    "#### <a name=\"32\">3.2. LangChain agents</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "An Agent is a wrapper around a model, which takes in user input and returns a response corresponding to an \"action\" to take and a corresponding \"action input\". With agents, an **LLM is used as a reasoning engine** to determine which actions to take and in which order.\n",
    "\n",
    "LangChain provides a utility to initialize an agent. To do so, we need to pass the following parameters:\n",
    "\n",
    "- **`tools`**: a list of tools that the model has access to\n",
    "- **`llm`**: the language model that will perform the reasoning and act process\n",
    "- **`agent`**: the type of agent that we want to initialize\n",
    "\n",
    "The example below initializes a \"Zero-shot React Description\" agent. Zero-shot means the agent functions on the current action only, i.e. it has no memory. The agent uses the ReAct framework to decide which tool to use, based solely on the tool's `description`. It is important to give the agent access to a correct set of tools, otherwise it will not be able to accomplish its objective. Additionally, if tools are not properly described, the agent won't know how to use them.\n",
    "\n",
    "The code below initializes an agent with the following capabilites:\n",
    "\n",
    "- identify current date\n",
    "- access to Python interpreter\n",
    "- web search capabilities (general, trips, hotels, flights)\n",
    "- wikipedia queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51db8c9-73cb-4ea6-a0dc-9e31cbb02c57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    date_tool,\n",
    "    PythonREPLTool(),\n",
    "    wikipedia_tool\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, handle_parsing_errors = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff984678-76a3-460e-aea1-ebb434f5ec3a",
   "metadata": {},
   "source": [
    "### Customizing the agent's prompt template\n",
    "\n",
    "LangChain's Zero-shot React Description agent orchestrates the sequence of thoughts-actions-observations via a default template that is stored in `agent.agent.llm_chain.prompt.template` as you can see below. \n",
    "\n",
    "For more control on the ReAct results, it is possible to **customize the LLM agent's prompt template**, as demonstrated in this [Custom LLM agent walkthrough](https://python.langchain.com/docs/modules/agents/how_to/custom_llm_agent). This way, one can force the agent to output the final answer in a special format or style. Similarly, one can make rules to the LLM explicit in the prompt template, for instance adding an instruction for the LLM to always use a particular tool as the first tool or enforcing a specific order constraint when calling the available tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd52af06-a91f-4efa-863c-65e565dc7692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "DateTool: Useful to retrieve the current date.\n",
      "Python_REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n",
      "wikipedia: Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [DateTool, Python_REPL, wikipedia]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "# Default prompt template of AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6fe9b4-f830-48e2-a835-1e438274a190",
   "metadata": {},
   "source": [
    "#### Util function to run ReAct queries\n",
    "\n",
    "The util function below will be used to run queries with and without ReAct for easy comparison of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcb40bd-e3a5-4922-b84e-3e34b54fd343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_standard_and_react(llm, agent, prompt):\n",
    "    \"\"\"\n",
    "    Utility function to prompt an LLM with a standard query and with ReAct through an agent \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mistral_prompt = f\"<s>[INST]{prompt}[/INST]\"\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            prompt\n",
    "        ),\n",
    "    ]\n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(prompt))\n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(\"### Without ReAct\"))\n",
    "    #display(Markdown(llm.invoke(messages).content))\n",
    "    display(Markdown(llm(prompt)))\n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(\"### With ReAct\"))\n",
    "    #{\"input\": \"What is the capital of France?\"}\n",
    "    #display(Markdown(agent.run({\"input\": mistral_prompt})))\n",
    "    agent.run(prompt)\n",
    "    display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46538f22-d171-4e41-b3ef-56240bb2da84",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <a name=\"4\">4. ReAct examples</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "It is time to put our agent to work. Let's create an agent with current time and Python capabilities.\n",
    "\n",
    "#### <a name=\"41\">4.1. Time awareness</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "The LLM can gain awareness of the current time, since it has access to our custom date tool. Compare the results obtained with the LLM as a ReAct agent versus standard prompting without ReAct:\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px\">\n",
    "    <h4>A note on security best practices with LLMs</h4>\n",
    "\n",
    "The Python REPL tool is used here as an example of what's possible to do with ReAct.\n",
    "<br/>\n",
    "This demo does not use or teach security best practices. You should not allow generative AI to run arbitrary code on production systems.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a8cec6-f98d-43ec-ad41-f896c610797d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I was born on March 22, 2000. How old am I today in years, months and days ?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Without ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To determine your age in years, months, and days, we need to calculate the difference between today's date and your date of birth. Let's start by finding out how many years have passed since your birth.\n",
       "\n",
       "You were born on March 22, 2000, which means that you have already celebrated your 22nd birthday this year. However, since we are not yet at the end of the year, we need to subtract one from the current year to get the number of full years you have lived.\n",
       "\n",
       "The current year is 2023, so you have lived for 2023 - 2000 = 23 years.\n",
       "\n",
       "Next, we need to find out how many months you have lived. Since your birthday is on March 22nd, we can assume that you have already celebrated your birthday this year. Therefore, we can calculate the number of months by subtracting the month of your birth from the current month and adding one to account for the fact that you have already celebrated your birthday this year.\n",
       "\n",
       "The current month is April, which is the fourth month of the year. Therefore, you have lived for 4 - 3 + 1 = 2 months this year.\n",
       "\n",
       "Finally, we need to find out how many days you have lived. Since your birthday is on March 22nd, we can assume that you have already celebrated your birthday this year. Therefore, we can calculate the number of days by subtracting the day of your birth from the current day.\n",
       "\n",
       "The current day is April 15th, which is 24 days after March 22nd.\n",
       "\n",
       "Therefore, you are 23 years, 2 months, and 24 days old today."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### With ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to know today's date.\n",
      "Action: DateTool.get_current_date()\n",
      "Action Input: -\u001b[0m\n",
      "Observation: DateTool.get_current_date() is not a valid tool, try one of [DateTool, Python_REPL, wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know today's date.\n",
      "Action: DateTool.get_current_date()\n",
      "Action Input: -\u001b[0m\n",
      "Observation: DateTool.get_current_date() is not a valid tool, try one of [DateTool, Python_REPL, wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI know the answer.\n",
      "Final Answer: 23 years, 2 months, 10 days.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"I was born on March 22, 2000. How old am I today in years, months and days ?\"\n",
    "run_standard_and_react(llm, agent, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf4742d7-d8d1-4da8-826b-ada7aa5536b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.agents.agent.AgentExecutor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bd4c3-1668-4431-9f14-fe2cf7b51bc6",
   "metadata": {},
   "source": [
    "#### <a name=\"42\">4.2. Calculator and Code interpreter</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "The ability to run Python code greatly enhances the performance of LLMs in some arithmetic as well as logical tasks with a clear algorithmic solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b28d2746-0d26-4b08-8d4f-c60eaa00105f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To find the square root of 2.5 million, we first convert it to a single number by moving the decimal point six places to the left, which gives us 2500.\n",
       "\n",
       "Now, let's estimate the square root of 2500. We know that 50 x 50 = 2500, so the square root of 2500 must be slightly more than 50.\n",
       "\n",
       "To get a more precise answer, we can use a calculator. When we do, we find that the square root of 2500 is approximately 50.00, which means that the square root of 2.5 million is approximately 500.\n",
       "\n",
       "Therefore, the square root of 2.5 million is 500. The answer is: 500."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Without ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To determine the square root of 2.5 million, we first convert it to a single number by moving the decimal point six places to the left, resulting in 2500.\n",
       "\n",
       "Next, we estimate the square root of 2500. We know that 50 multiplied by 50 equals 2500, so the square root of 2500 must be slightly more than 50.\n",
       "\n",
       "To get a more accurate answer, we can use a calculator. When we do, we find that the square root of 2500 is approximately 50.00. This means that the square root of 2.5 million is approximately 500.\n",
       "\n",
       "Hence, the square root of 2.5 million is 500. The answer is: 500."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### With ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI know the final answer.\n",
      "Final Answer: 500\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXAMPLE 1\n",
    "# Arithmetic calculation that an LLM might get wrong\n",
    "\n",
    "prompt = llm(\"What's the square root of 2.5 million?\")\n",
    "run_standard_and_react(llm, agent, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c99460e-079e-46dd-8807-5cc0cc4d3341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To invert the letters of the given words and sort them in reverse order, we can follow these steps:\n",
       "\n",
       "1. Define a list of words: `words = [\"apple\", \"Banana\", \"Cherry\", \"pear\", \"elderberry\"]`\n",
       "2. Create an empty list to store the inverted and sorted words: `inverted_sorted_words = []`\n",
       "3. Iterate over each word in the list:\n",
       "4. Invert the letters of the word: `inverted_word = word[::-1]`\n",
       "5. Sort the inverted word in reverse order: `sorted_word = sorted(inverted_word, reverse=True)`\n",
       "6. Append the sorted word to the `inverted_sorted_words` list: `inverted_sorted_words.append(''.join(sorted_word))`\n",
       "7. Print the `inverted_sorted_words` list: `print(inverted_sorted_words)`\n",
       "\n",
       "Here's the complete code:\n",
       "\n",
       "```python\n",
       "words = [\"apple\", \"Banana\", \"Cherry\", \"pear\", \"elderberry\"]\n",
       "inverted_sorted_words = []\n",
       "\n",
       "for word in words:\n",
       "    inverted_word = word[::-1]\n",
       "    sorted_word = sorted(inverted_word, reverse=True)\n",
       "    inverted_sorted_words.append(''.join(sorted_word))\n",
       "\n",
       "print(inverted_sorted_words)\n",
       "```\n",
       "\n",
       "Output:\n",
       "\n",
       "```\n",
       "['yrrehC', 'ananaB', 'elppae', 'raepr', 'yrrebdelet']\n",
       "```\n",
       "\n",
       "Note: The output is case-sensitive, so the capital letters are sorted before the lowercase letters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Without ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To invert the letters of the given words and sort them in reverse order, we can follow these steps:\n",
       "\n",
       "1. Define a list of words: `words = [\"apple\", \"Banana\", \"Cherry\", \"pear\", \"elderberry\"]`\n",
       "2. Create an empty list to store the inverted and sorted words: `inverted_sorted_words = []`\n",
       "3. Iterate over each word in the list:\n",
       "4. Invert the letters of the word: `inverted_word = word[::-1]`\n",
       "5. Sort the inverted word in reverse order: `sorted_word = sorted(inverted_word, reverse=True)`\n",
       "6. Append the sorted word to the `inverted_sorted_words` list: `inverted_sorted_words.append(''.join(sorted_word))`\n",
       "7. Print the `inverted_sorted_words` list: `print(inverted_sorted_words)`\n",
       "\n",
       "Here's the complete code:\n",
       "\n",
       "```python\n",
       "words = [\"apple\", \"Banana\", \"Cherry\", \"pear\", \"elderberry\"]\n",
       "inverted_sorted_words = []\n",
       "\n",
       "for word in words:\n",
       "    inverted_word = word[::-1]\n",
       "    sorted_word = sorted(inverted_word, reverse=True)\n",
       "    inverted_sorted_words.append(''.join(sorted_word))\n",
       "\n",
       "print(inverted_sorted_words)\n",
       "```\n",
       "\n",
       "Output:\n",
       "\n",
       "```\n",
       "['yrrehC', 'ananaB', 'elppae', 'raepr', 'yrrebdelet']\n",
       "```\n",
       "\n",
       "Note: The output is case-sensitive, so the capital letters are sorted before the lowercase letters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### With ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to define a list of words.\n",
      "Action: Python_REPL\n",
      "Action Input: words = [\"apple\", \"Banana\", \"Cherry\", \"pear\", \"elderberry\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to create an empty list to store the inverted and sorted words.\n",
      "Action: Python_REPL\n",
      "Action Input: inverted_sorted_words = []\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to iterate over each word in the list.\n",
      "Action: Python_REPL\n",
      "Action Input: for word in words:\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIndentationError(\"expected an indented block after 'for' statement on line 1\", ('<string>', 1, 19, 'for word in words:\\n', 1, -1))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to iterate over each word in the list.\n",
      "Action: Python_REPL\n",
      "Action Input: for word in words:\n",
      "    inverted_word = word[::-1]\n",
      "    sorted_word = sorted(inverted_word, reverse=True)\n",
      "    inverted_sorted_words.append(''.join(sorted_word))\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to print the inverted_sorted_words list.\n",
      "Action: Python_REPL\n",
      "Action Input: print(inverted_sorted_words)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m['pplea', 'nnaaaB', 'yrrheC', 'rpea', 'yrrrleeedb']\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI know the final answer.\n",
      "Final Answer: ['pplea', 'nnaaaB', 'yrrheC', 'rpea', 'yrrrleeedb']\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXAMPLE 2\n",
    "# Sorting of words that an LLM migth get wrong\n",
    "\n",
    "prompt = llm(\"Invert the letters of the following words and sort them in reverse order: apple, Banana, Cherry, pear, elderberry\")\n",
    "run_standard_and_react(llm, agent, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6c957-5c3c-47f6-bac7-062c360f215a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto; padding-left: 50px; padding-right: 50px\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\"><b>Try solving similar tasks involving math and code.</b></br> For example, you can ask the model to compute compound interest over the years, or to answer arithmetic or trigonometric math problems.</code>\n",
    "</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f98200a0-7f53-4787-8383-6da600fca3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005ca96-3ede-4bb4-911b-64a0de417769",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <a name=\"43\">4.3. Knowledge-intensive tasks</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We will now use an agent enhanced with web search and Wikipedia query capabilites and probe it in its ability to answer questions about facts of the real world. The example below requires certain knowledge about persons and facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ade4cd1-593b-4fad-ab80-06e0437327c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Amazon Bedrock is the AWS service that provides access to foundation models. It is a fully managed service that makes foundation models from leading AI startups and Amazon available via an API. Amazon Bedrock allows developers to easily build applications that use foundation models to generate text, create images, extract information from documents, moderate content, automate customer support, and more."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Without ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Amazon Bedrock is a fully managed AWS service that grants access to foundation models from leading AI startups and Amazon. It enables developers to effortlessly build applications that utilize foundation models for various tasks, such as generating text, creating images, extracting information from documents, moderating content, automating customer support, and more.\n",
       "\n",
       "With Amazon Bedrock, developers can leverage foundation models from AI startups like AI21 Labs, Anthropic, Stability AI, and Amazon Titan. This service offers benefits like easy integration, scalability, cost-effectiveness, and customization.\n",
       "\n",
       "Developers can integrate foundation models into their applications with just a few lines of code, thanks to the Amazon Bedrock API. The service is designed to handle high-volume requests, making it suitable for applications requiring real-time responses. Additionally, Amazon Bedrock offers pay-as-you-go pricing, making it a cost-effective solution for developers.\n",
       "\n",
       "Moreover, Amazon Bedrock allows developers to customize foundation models with their own data, fine-tune them for specific use cases, and monitor model performance with built-in tools. This enables developers to create applications that cater to their unique needs and requirements.\n",
       "\n",
       "Overall, Amazon Bedrock is a powerful tool for developers looking to build applications that leverage the capabilities of foundation models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### With ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to generate the final answer\n",
      "Final Answer: Amazon Bedrock is the AWS service that provides access to foundation models. It is a fully managed service that makes foundation models from leading AI startups and Amazon available via an API. Amazon Bedrock allows developers to easily build applications that use foundation models to generate text, create images, extract information from documents, moderate content, automate customer support, and more.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = llm(\"Which AWS service provides access to foundation models?\")\n",
    "run_standard_and_react(llm, agent, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1c1d0-fa5b-431c-a0ef-7eab9d473b68",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto; padding-left: 50px; padding-right: 50px\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\"><b>Try solving similar knowledge-based tasks.</b></br> For example, you can ask the model to tell you facts about famous actors, scientists, singers, or historical characters.</code>\n",
    "</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "346f232d-c292-44b5-bbb0-36d58b1c78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021807ee-048f-4b3a-960b-9b69fb7b2390",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <a name=\"44\">4.4. Decision-making tasks</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We will now leverage the planning capabilities of the agent enhanced with custom web search to ask the model to put together complex plans involving a set of decision. The example below is about deciding where to go on an upcoming impromptu vacation.\n",
    "\n",
    "**Note:** We were using a live search API like  [DuckDuckGo](https://duckduckgo.com/) in this example for up-to date results but started seeing `ratelimiting exception by duckduckgo`. For learning purposes we replaced it with Wikipedia search and recommend using a live search tool with proper API keys for a use-case like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3bb7f99-4bbc-4125-96f2-5b6156ee7eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I'm happy to help you plan your last-minute vacation. Given that you live in Munich and have two options, Tokyo or Las Vegas, let's examine each choice and select the best one.\n",
       "\n",
       "Tokyo is a bustling metropolis with a rich cultural heritage, delicious food, and exciting attractions. On the other hand, Las Vegas is known for its casinos, nightlife, and entertainment. If you're looking for a more cultural experience, Tokyo might be the better choice. If you're looking for a more relaxed and entertaining vacation, Las Vegas might be the way to go.\n",
       "\n",
       "Based on your preferences, let's plan a one-week vacation to Tokyo. Here's a suggested itinerary for each day:\n",
       "\n",
       "Day 1: Arrival and Shibuya\n",
       "- Arrive in Tokyo and check into your hotel in Shibuya.\n",
       "- Explore the famous Shibuya Crossing and take in the vibrant atmosphere.\n",
       "- Visit the Meiji Shrine, a peaceful Shinto shrine surrounded by a forest.\n",
       "- Enjoy dinner at a local izakaya (Japanese pub) and try some delicious Japanese dishes.\n",
       "\n",
       "Day 2: Asakusa and Ueno\n",
       "- Visit the Senso-ji Temple, Tokyo's oldest temple, in Asakusa.\n",
       "- Explore the Nakamise Shopping Street, a traditional shopping street with various souvenirs and snacks.\n",
       "- Visit the Ueno Park, a large public park with museums, temples, and a zoo.\n",
       "- Enjoy lunch at a traditional Japanese restaurant and try some sushi or ramen.\n",
       "\n",
       "Day 3: Tokyo Tower and Roppongi\n",
       "- Visit the Tokyo Tower, a famous landmark that offers panoramic views of the city.\n",
       "- Explore the Roppongi district, known for its nightlife and entertainment.\n",
       "- Visit the Mori Art Museum, an art museum with contemporary art exhibitions.\n",
       "- Enjoy dinner at a high-end restaurant in Roppongi and try some Japanese cuisine.\n",
       "\n",
       "Day 4: Tokyo Disneyland or DisneySea\n",
       "- Spend the day at Tokyo Disneyland or DisneySea, two of the most popular theme parks in Japan.\n",
       "- Enjoy the rides, shows, and attractions at the park.\n",
       "- Have lunch at one of the many restaurants in the park.\n",
       "\n",
       "Day 5: Akihabara and Odaiba\n",
       "- Visit Akihabara, the electronics district, and explore the many shops selling electronics, anime, and manga.\n",
       "- Visit the Odaiba district, a man-made island with shopping malls, amusement parks, and entertainment.\n",
       "- Visit the teamLab Borderless museum, an immersive digital art museum.\n",
       "- Enjoy dinner at a conveyor belt sushi restaurant in Akihabara.\n",
       "\n",
       "Day 6: Shinjuku and Harajuku\n",
       "- Visit the Shinjuku district, known for its skyscrapers, shopping, and nightlife.\n",
       "- Visit the Tokyo Metropolitan Government Building, which offers panoramic views of the city.\n",
       "- Visit the Harajuku district, known for its fashion and youth culture.\n",
       "- Visit the Meiji Jingu Gaien Icho Namiki Avenue, a tree-lined street with gingko trees.\n",
       "- Enjoy dinner at a teppanyaki restaurant in Shinjuku.\n",
       "\n",
       "Day 7: Departure\n",
       "- Check out of your hotel and head to the airport for your flight back to Munich.\n",
       "- Enjoy a final meal in Tokyo before leaving.\n",
       "\n",
       "I hope this itinerary helps you plan your last-minute vacation to Tokyo. Let me know if you have any questions or if you need any further assistance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Without ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for your assistance. I'm leaning towards Tokyo because I'm interested in Japanese culture, and I'm excited to try the food. I'm also looking forward to visiting the Meiji Shrine and the teamLab Borderless museum. I'm not sure if I'll have time to visit both Tokyo Disneyland and DisneySea, so I'll have to decide which one to visit. I'll also need to research the best way to get around Tokyo and the cost of transportation. I appreciate your help in planning my vacation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### With ReAct"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to know what is the date today.\n",
      "Action: DateTool\n",
      "Action Input: get_date()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2024-07-10\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1_euro.to_yen())\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 8, 'print(1_euro.to_yen())', 1, 8))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.to_yen())\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, 'print(1.0_euro.to_yen())', 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate_to('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate_to('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate_to('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate_to('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate_to('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate_to('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate_to('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate_to('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate_to('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate_to('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate_to('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate_to('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to know the exchange rate between Euro and Japanese Yen.\n",
      "Action: Python_REPL\n",
      "Action Input: print(1.0_euro.exchange_rate('JPY'))\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSyntaxError('invalid decimal literal', ('<string>', 1, 10, \"print(1.0_euro.exchange_rate('JPY'))\", 1, 10))\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instruction = \"\"\"Help me make a one-week plan for a last-minute vacation for next week.\n",
    "I live in Munich and I'm considering either Tokyo or Las Vegas.\n",
    "Once you've chosen the best destination, produce a plan with activities for each day.\"\"\"\n",
    "\n",
    "prompt = llm(instruction)\n",
    "run_standard_and_react(llm, agent, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b78d15-5fd9-436a-9d63-abb980c34e6e",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto; padding-left: 50px; padding-right: 50px\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\"><b>Try solving similar planning tasks.</b><br/>For example, you can ask the model to plan a party and make a shopping list to be ordered in Amazon.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c97d31d-440c-4c34-8eea-43e599f8fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc138d-23bf-4bfe-9e3e-58d10f85e58e",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We have examined a series of tasks that are typically challenging for LLMs to solve, as they involve time awareness, compute capabilities, factual knowledge about current and past persons and events, and the ability to reason and make decisions. The ReAct approach allows the model to generate verbal reasoning traces and actions for a task. This helps make LLM responses more explainable and reduces hallucinations compared to CoT, giving users a better chance of solving the tasks they want.\n",
    "\n",
    "It is important to keep in mind that current agents relies on natural language as an interface between LLMs and additional tools. However, the **reliability of model outputs with ReAct is questionable**, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, a great deal of work needs to be invested in crafting appropriate prompts and in parsing model output correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953e3fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto; padding-left: 50px; padding-right: 50px\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\"><b>Well done on completing the lab. Now it's time for you to get creative.</b></p>\n",
    "    <p style=\" text-align: center; margin: auto;\">Try getting the model to solve other tasks for you.</p>\n",
    "    <p style=\" text-align: center; margin: auto;\">You can for instance incorporate finance questions using  <code>YahooFinanceNewsTool</code> or medical informating using the <code>PubmedQueryRun</code> as tools.</p>\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7873a3dd-8d5b-454b-8da8-09e57aabd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CODE HERE ####################\n",
    "\n",
    "\n",
    "\n",
    "############## END OF CODE ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee696c1",
   "metadata": {},
   "source": [
    "# Thank you!\n",
    "\n",
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
